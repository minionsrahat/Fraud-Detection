{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from pyod.models.knn import KNN \n",
    "import pyod\n",
    "from pyod.utils.data import evaluate_print\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.font_manager\n",
    "import numpy as np\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.utils.data import generate_data, get_outliers_inliers\n",
    "import seaborn as sns \n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('bsNET140513_032310.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Weight</th>\n",
       "      <th>typeTrans</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'C1093826151'</td>\n",
       "      <td>'M348934600'</td>\n",
       "      <td>4.55</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'C352968107'</td>\n",
       "      <td>'M348934600'</td>\n",
       "      <td>39.68</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'C2054744914'</td>\n",
       "      <td>'M1823072687'</td>\n",
       "      <td>26.89</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'C1760612790'</td>\n",
       "      <td>'M348934600'</td>\n",
       "      <td>17.25</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'C757503768'</td>\n",
       "      <td>'M348934600'</td>\n",
       "      <td>35.72</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Source         Target  Weight            typeTrans  fraud\n",
       "0  'C1093826151'   'M348934600'    4.55  'es_transportation'      0\n",
       "1   'C352968107'   'M348934600'   39.68  'es_transportation'      0\n",
       "2  'C2054744914'  'M1823072687'   26.89  'es_transportation'      0\n",
       "3  'C1760612790'   'M348934600'   17.25  'es_transportation'      0\n",
       "4   'C757503768'   'M348934600'   35.72  'es_transportation'      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Fraud and Non fraud sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    587443\n",
       "1      7200\n",
       "Name: fraud, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fraud'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df2=df.copy()\n",
    "df2.loc[:,['typeTrans']]=le.fit_transform(df2.loc[:,['typeTrans']])\n",
    "df2.loc[:,['Target']]=le.fit_transform(df2.loc[:,['Target']])\n",
    "df2.loc[:,['Source']]=le.fit_transform(df2.loc[:,['Source']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df2[df2.columns.drop(['fraud'])].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "iso = IsolationForest(contamination=0.05)\n",
    "yhat = iso.fit_predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=df2.values\n",
    "mask = yhat == -1\n",
    "outlier_values_if=pd.DataFrame(data2[mask, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29733"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " len(outlier_values_if)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    23821\n",
       "1.0     5912\n",
       "Name: 4, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_values_if[4].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model Without Applying Any sampling Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test=train_test_split(df2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest=test.drop('fraud',axis=1)\n",
    "ytest=test.fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print('True positive = ', cm[1][1])\n",
    "    print('False positive = ', cm[0][1])\n",
    "    print('False negative = ', cm[1][0])\n",
    "    print('True negative = ', cm[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_evaluation_metrics(y_true, y_pred):\n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print('Accuracy: %f' % accuracy)\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    print('Precision: %f' % precision)\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    print('Recall: %f' % recall)\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearSVC()\n",
    "model.fit(train.drop('fraud',axis=1),train.fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare=pd.DataFrame()\n",
    "compare['true']=np.array(ytest)\n",
    "compare['preicted']=np.array(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      "\n",
      "True positive =  862\n",
      "False positive =  54\n",
      "False negative =  888\n",
      "True negative =  146857\n",
      "---------------------------------------\n",
      "\n",
      "Evaluation_metrics \n",
      "\n",
      "Accuracy: 0.993663\n",
      "Precision: 0.941048\n",
      "Recall: 0.492571\n",
      "F1 score: 0.646662\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix \\n')\n",
    "print_confusion_matrix(compare['true'],compare['preicted'])\n",
    "print('---------------------------------------')\n",
    "print('\\nEvaluation_metrics \\n')\n",
    "print_evaluation_metrics(compare['true'],compare['preicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn, fp, fn, tp --->  146857 54 888 862\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(compare['true'],compare['preicted']).ravel()\n",
    "print(\"tn, fp, fn, tp ---> \", tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Train Model With Applying Undersampling  Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_rus, y_rus = rus.fit_resample(train.drop('fraud',axis=1),train.fraud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Fraud and Non Fraud sample after resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5450\n",
       "0    5450\n",
       "Name: fraud, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_rus.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(class_weight='balanced')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearSVC(class_weight='balanced')\n",
    "model.fit(X_rus, y_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(xtest)\n",
    "compare=pd.DataFrame()\n",
    "compare['true']=np.array(ytest)\n",
    "compare['preicted']=np.array(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix For Undersampling Technique\n",
      "\n",
      "True positive =  1462\n",
      "False positive =  5472\n",
      "False negative =  288\n",
      "True negative =  141439\n",
      "---------------------------------------\n",
      "\n",
      "Evaluation_metrics For Undersampling Technique\n",
      "\n",
      "Accuracy: 0.961254\n",
      "Precision: 0.210845\n",
      "Recall: 0.835429\n",
      "F1 score: 0.336711\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix For Undersampling Technique\\n')\n",
    "print_confusion_matrix(compare['true'],compare['preicted'])\n",
    "print('---------------------------------------')\n",
    "print('\\nEvaluation_metrics For Undersampling Technique\\n')\n",
    "print_evaluation_metrics(compare['true'],compare['preicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.961254\n",
      "Precision: 0.210845\n",
      "Recall: 0.835429\n",
      "F1 score: 0.336711\n"
     ]
    }
   ],
   "source": [
    "print_evaluation_metrics(compare['true'],compare['preicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #  Train Model With Applying Oversampling  Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomOverSampler(random_state=42)\n",
    "X_ros, y_ros = rus.fit_resample(train.drop('fraud',axis=1),train.fraud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaling = MinMaxScaler(feature_range=(-1,1))\n",
    "x_train=scaling.fit_transform(X_ros)\n",
    "x_test=scaling.fit_transform(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Total Fraud and Non Fraud sample after resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    440532\n",
       "0    440532\n",
       "Name: fraud, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ros.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(class_weight='balanced')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearSVC(class_weight='balanced')\n",
    "model.fit(x_train, y_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(x_test)\n",
    "compare=pd.DataFrame()\n",
    "compare['true']=np.array(ytest)\n",
    "compare['preicted']=np.array(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix For Oversampling Technique\n",
      "\n",
      "True positive =  1552\n",
      "False positive =  7882\n",
      "False negative =  198\n",
      "True negative =  139029\n",
      "---------------------------------------\n",
      "\n",
      "Evaluation_metrics For Oversampling Technique\n",
      "\n",
      "Accuracy: 0.945648\n",
      "Precision: 0.164511\n",
      "Recall: 0.886857\n",
      "F1 score: 0.277539\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix For Oversampling Technique\\n')\n",
    "print_confusion_matrix(compare['true'],compare['preicted'])\n",
    "print('---------------------------------------')\n",
    "print('\\nEvaluation_metrics For Oversampling Technique\\n')\n",
    "print_evaluation_metrics(compare['true'],compare['preicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Train Model With Applying SMOTE  Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy='minority')\n",
    "X_sm, y_sm = smote.fit_resample((train.drop('fraud',axis=1)),train.fraud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaling = MinMaxScaler(feature_range=(-1,1))\n",
    "x_train=scaling.fit_transform(X_sm)\n",
    "x_test=scaling.fit_transform(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Total Fraud and Non Fraud sample after resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    440532\n",
       "0    440532\n",
       "Name: fraud, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(class_weight='balanced')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearSVC(class_weight='balanced')\n",
    "model.fit(x_train, y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(x_test)\n",
    "compare=pd.DataFrame()\n",
    "compare['true']=np.array(ytest)\n",
    "compare['preicted']=np.array(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix For SMOTE Technique\n",
      "\n",
      "True positive =  1551\n",
      "False positive =  9600\n",
      "False negative =  199\n",
      "True negative =  137311\n",
      "---------------------------------------\n",
      "\n",
      "Evaluation_metrics For SMOTE Technique\n",
      "\n",
      "Accuracy: 0.934085\n",
      "Precision: 0.139091\n",
      "Recall: 0.886286\n",
      "F1 score: 0.240446\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix For SMOTE Technique\\n')\n",
    "print_confusion_matrix(compare['true'],compare['preicted'])\n",
    "print('---------------------------------------')\n",
    "print('\\nEvaluation_metrics For SMOTE Technique\\n')\n",
    "print_evaluation_metrics(compare['true'],compare['preicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Train Model With Applying  SMOTETomek  Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTETomek\n",
    "from imblearn.combine import SMOTETomek\n",
    "smk = SMOTETomek()\n",
    "X_smk, y_smk = smk.fit_resample(train.drop('fraud',axis=1),train.fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    440337\n",
       "0    440337\n",
       "Name: fraud, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_smk.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaling = MinMaxScaler(feature_range=(-1,1))\n",
    "x_train=scaling.fit_transform(X_smk)\n",
    "x_test=scaling.fit_transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(class_weight='balanced')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearSVC(class_weight='balanced')\n",
    "model.fit(x_train, y_smk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(x_test)\n",
    "compare=pd.DataFrame()\n",
    "compare['true']=np.array(ytest)\n",
    "compare['preicted']=np.array(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix For SMOTE Technique\n",
      "\n",
      "True positive =  1553\n",
      "False positive =  9530\n",
      "False negative =  197\n",
      "True negative =  137381\n",
      "---------------------------------------\n",
      "\n",
      "Evaluation_metrics For SMOTE Technique\n",
      "\n",
      "Accuracy: 0.934569\n",
      "Precision: 0.140125\n",
      "Recall: 0.887429\n",
      "F1 score: 0.242032\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix For SMOTE Technique\\n')\n",
    "print_confusion_matrix(compare['true'],compare['preicted'])\n",
    "print('---------------------------------------')\n",
    "print('\\nEvaluation_metrics For SMOTE Technique\\n')\n",
    "print_evaluation_metrics(compare['true'],compare['preicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
